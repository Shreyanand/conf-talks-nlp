Speaker 0    00:00:00    Welcome to another operate. First data science, community meetup. I am a Kasha. I'm a data scientist in the AIOps team. And today we have SU who's also a data scientist in the AIOps team. He's gonna talk about the non anomaly detection using the hierarchical temporal memory algorithm on the operate first data. So over to you soya.  
Speaker 1    00:00:24    Thank you very much. Can everybody see my slide?  
Speaker 0    00:00:37    Yes.  
Speaker 1    00:00:38    All right, so thank you very much, Aun. Hi everyone. This is soya. Prash a data scientist in a ops team, and now open services team working with manager Michael Clifford. And today I want to give you a brief intro about working principle of hierarchical temporal memory and its application to animal detection. Now today's stock include a, a brief comparison of great neural networks, which it with HDM and, uh, which is then followed by the introductions about hierarchical temporal memory and its working mechanisms. I will then conclude my talk by giving you a brief intro about animal detections and showing a little bit demo about how I applied this HDM algorithm in detecting the animality in CPU users, data from operate first cluster.  
Speaker 1    00:01:31    So artificial intelligence, whenever I, I talk about artificial intelligence, deep neural networks has, uh, comes in picture. Um, so deep neural networks have immense applications in different industrial fields. Be it healthcare, be technology like fraud, detections, and so on. So, but it does have a lot of I limitations as well. Like it needs thousands, if not million samples to train on it, find very hard to adapt, to continually changing data and surprises. And it is also susceptible to noise and easily can be fooled. The source that I link there is a paper depicting where a group of scientists based a structure, uh, based a speaker on the traffic science like stop sign and they fool the machine learning system in classifying the object. Uh, you can check that paper over there as well. Uh, so, so therefore deep learning dip neural networks, instead of artificial intelligence can be said as a framework for assistive intelligence more so it does not work as our brain does and cannot lead to the true artificial intelligence,  
Speaker 1    00:02:48    HTM hierarchical temporal memory, which is a theoretical framework for both biological and generalized machine learnings. It is based on the latest understanding of neocortex. Neocortex is a part of our human brain. Um, it only requires few hundreds of samples to learn. One of the important characteristics is learn. It learns unsupervised as it goes and easily handles changing data and surprises. It is immune to up to 40% of noise in the data HTM. And as the name suggest is it's, uh, hierarchical, it's composed of levels of stack cells, which work on the algorithm, the temporal, it operates on time series, data and memory. It does not just relies on the present instant of the data, but relies also on the memory or the previous state of the data as well. And this really opens the way for truly intelligent systems. Now, let's talk a bit about how it got in picture got into the present day.  
Speaker 1    00:03:51    It is in, so Jeff Hawkins who originally invented a Palm pilot, which is something like a very ative smartphone like devices, uh, Jeff Hawkins, and Sandra Beki wrote on intelligence book on 2004, uh, explaining about the mechanism of human, uh, brain, how it remembers, uh, different things and what intelligence is, uh, the core concept of hierarchical temper, a memory in that book in 2005, they, he formed a research lab, which, uh, which works on the rivers engineer engineering of the neocortex. So he wanted to understand the working mechanism of neocortex so that he can apply it to the technology framework. In 2014, this project got open sourced, uh, uh, with the GitHub handle, new new pick. Uh, the API over here used is Python 2.7 and C plus plus in 2015, uh, there's a community fork of new pick.org got developed, uh, known as HTM dot with API of Python, 3.7 plus NC plus plus in 21, a thousand brains theory of the Hawkings. That is the new book that's got published recently. And here you can find further explanations of, uh, more detailed mechanisms of how HTM algorithm works and how it is indirect correspondence to how our human brain works. So as J haw says, SM is it is, it is really directing to the true, uh, intelligence system and HDM or Numenta is constantly evolving with Numenta open research.  
Speaker 1    00:05:39    So Neo otics, we talked about HDM being a conceptu, similar to the neocortex. What is neocortex? Neocortex is the part that you are seeing the picture. It's the part of the brain covering the brain. It's the size of the large table napkin, which is like 50 by 50 square centimeters. That's it, uh, whatever I do, whatever. I think how I behave completely dependence on completely depends on this neocortex, whatever I'm speaking right now, whatever you are listening right now, it's, it's all because of these neocortex. And it, it, it constitute of 75% of the brain's volume, which is 2.5 millimeter thick. It contains almost a 20 billion neurons, tens of thousands of signups per neurons signups are the intersections just to be clear intersections, which, uh, which acts as a memory or some spike in the new one of the important characteristic is it is partially active.  
Speaker 1    00:06:43    Now we just said there are 20 billion neurons, but also only billion neurons does not take part at once inactivity in any activity. So only 2% of spiking of the neuron takes place at one particular time. And it's constantly predicting its input. And this is also a fascinating feature of what human brain, uh, which I also, uh, came to know like our brain is constantly predicting. If you are, uh, if you are going somewhere, you're predicting that you are reached there in that moment of time. If you're talking to somebody, you are predicting some, the, some input from others as well. So whatever you do, it's, it's always a prediction. And if the prediction does not work perfectly, you learn something new. So that's how the memory gets added in your brain. And that's how you become more experienced. And it learns the model of the world. That's how it learns the model of the world by predicting constant.  
Speaker 1    00:07:43    So more into the Neo cortex, how does the new cortex looks like this is another fascinating feature. All areas in the Neo cortex looks the same, which means the new cortex that is connected to my eye and the new cortex that is connected to my ear. They are same, which actually means they perform the same basic function, computational speaking. They have the same basic algorithm. So let's say I'm speaking at the moment. Um, you are hearing something you are seeing me. You are, uh, your eye is transferring my in image in my, in your brain ear is transferring my voice in your brain. Although the nerve that acts as an end quarter from the eye to the brain and ear to the brain that end quarter end codes in the same format, when it reaches the new cortex, that's pretty fascinating feature, which we have in, in our brain.  
Speaker 1    00:08:45    So the main thing is we have the same algorithm. Everything works in the same algorithm. So what makes one region visual and another touch depends upon what nerve they're connected to nerve. I can correlate it with, uh, what end quarter machine that they are connected to. The basic unit of replications is the cortical column, which we can see in the picture, each individual column, one millimeter square each. And we have about 2 million of 10, like so logically a cortical column is the basic unit of computation. If you move deeper into the cortical column, we can see thousands of neurons over here, and we can also see different layers of neurons over here. This is the real image of cortical column, where we have different layers of neuron. So basically a Al column has different layers of neuron, Adina, different mini columns. And these neurons are connected both horizontally and vertically.  
Speaker 1    00:09:51    So any way the T of information can takes place, it is very complex thing. So whatever the column does must also be complex and whatever the column does. So does the neocortex. That means each qual column has a very complex characteristics, which means the neocortex has a complex algorithm. If we move on coming back to the deep neural net neuron, uh, the figure on the right hand side is, uh, is a based on 1957 concept of perceptron where we have weights. We have inputs and these weights, which are generally, um, compared with the synapses, they are summed up in a neuron like format and to get the output, we pass it through the activation function, which are generally nonlinear. So that's how the process takes place. Basic process takes place. It is then, uh, converted into this deep learning neuros composed of large hidden layers, which has which in turn many applications.  
Speaker 1    00:11:02    So the basic concept behind is deep neural networks are the arrangement of weights in the learning process, but our human brain does not behave like this. We don't have any weight feature inside our brain and Jeff Hawkins. What he wanted to do is don't, he does not want it to mimic this weight feature in the technology. Instead, he wanted to mimic the, the brain mechanism in the algorithm let's move forward. So what is the structure of the real neuron, the structure on the right hand side that depicts the real neuron. It has den rights. It has a, and it has pro den rights at the center. Now sinuses have intersections. There are 5k to 30 KCI signups in the then rights. Now out of these signs, 10% can cause neural spike. So there is only out of these much out of hundred percent, only 10%, which are in the proximity of the cell.  
Speaker 1    00:12:13    Cause a new spike. Now for many years, people didn't know about what this 90% of this synopsis does. Are they just therefore being there or are, do they have any kind of significance? Well, it turns out that these then rights are, are called, which are called distill in rights are pattern detectors. They do not make a neural spike. Instead they transform the neuron, transform the point into the predictive state. Now what is the predictive state is compared to inactive neuron, which does not have any spike and compared to the, uh, spiked neuron, which is definitely predicting that form. The intermediate state is the predictive state. The predictive state is the one. If, if the similar input fires, if the, if the similar input reaches the brain or the ne or cortex or neuron, then the neuron in the predictive state fires faster. So if there is a higher chance of predicting something means the and rights in the, in the vicinity of neurons are in the predictive state. If we move on how HTM is, um, compared with this brain, uh, working mechanism now, HTM is not, don't attempt to model all aspect of biological neurons, but they, they only attempt to model some essential feature of the neurotics. So as we have over here, we have these layers of cells. These are basically the grid cells, which have come later on. So these grid cells, uh, behave like the neurons. These grid cells behave like the, uh, layers of neurons.  
Speaker 1    00:14:27    So HTM neuron state depends on the position and number of activated signups, not in the sum of waste. So depending upon whether the given cell in this grid is activated or not, it depends, the given information is, is recorded.  
Speaker 1    00:14:47    Now we were learning. Now one interesting thing, the signups is signups. Whenever there's a formation of sign, as it learns something new, it stores information. And if, if, if the brain does not want that information, then the signups is, uh, is disconnected. So in that is in the biology sense, how in the HTM signups, HTM algorithm sense, we call it a permanence, which is the signup state, a zero, zero permanence is the state where then right, and action are disconnected. Nothing is doing nothing. The neuron is doing nothing. However, one state is the neuro is doing some work is in active state, maybe in 0.3. It is some per predictive state. So this learning offers by incrementing or decrementing. The signups permanence sign is disconnected for a permanence under the threshold. Uh, signups is connected for a permanence over a threshold. So there is some T sold off threshold value related with the disconnection and the connection of these synapses, if we move on.  
Speaker 1    00:16:04    So if we come back to the layer of Al column, and if we want to mimic these layers of Al column with the sequence memory, what we see over here is if we take a part of this, let's say these are the layers of neuron in a cortical column. And we take this layers as the layers of different grid, which we, uh, which we compare this with the neurons. So as we can see the neurons in, in some cells, all the columns are active, that is given by the duck, uh, seed. And in some cells, only one neuron or two or three neurons are active per column.  
Speaker 1    00:16:47    This is called a sequence memory. Now, if I do the top projections of this, of this, uh, work, uh, of this column framework and put the darker line for at least one active neuron in the crib, then I'll form this type of representation. If I see this, uh, this, if I see this structure in a top view and form or shape like this, it'll form a good grid structure, which is called the sparse distributed representation. And it is, it is one of the most important concept in terms of hierarchical temporal memory, to understand more about it. What are, or S Sparke distributor to presentations SDRs are how brain solve the problem of representing knowledge. It is used in a context of every aspect of cognitive functions we were discussing before. Like, if, if we, if we, if I hear something that information from my ear through some nerve goes to the brain, it is encoded into something and that something is sparse distributor representation in terms of HTM, it is the representation that the algorithm can understand. Whatever input signal is be it visuals be numeric, be it categorical, anything. It can be converted into a sparse distributor representation. And once it is converted into this SDRs, the algorithm can understand other thing. Now, each beat has a semantic meaning, meaning if we have two spouses to representation as shown over here, and if we see there is some overlap in these representations, like over here, like over here, the more the overlap, the more similar is meaning of these representations.  
Speaker 1    00:18:54    Like if I say the sparse dis distributor representation of tea and coffee are much similar compared to tea and biscuit, they are completely different Now. And it's capacity is also very high, like for 2048 bit, and 2% are sick. That means 2% sparsity, only 2% of the neurons are active. We have 10 to the power, 84 unique patents. And this capacity was a calculator using this formula, given the number of bits that is 2048 bits. We have the number of orbits. Uh, we ha uh, factorial, uh, divided by the number of OFS factorial. Now, as we see these two presentations with shared BES have some shared semantic informations, comparing two representation is as simple as taking the intersections of two ins sets. Spars distributed to presentations are inherently fault tolerant and noise tolerant to presentations. If we move along,  
Speaker 1    00:20:02    Now we have this past distributor to presentation. We have this neuron from this, uh, we have this HTM neuron from this HTM neuron. We deriv the different grid cells taking one grid cells over here and taking one column. If I, if I input some feet forward, uh, if I give some feet forward input to this thing, to this column, then what happens is all the neurons on this column gets fired. That means gets active. Let us take two different cases. The first is the case of no predictions. And the second is the case of predictions. Now let's say a time is, goes to zero. My brain does not know anything. My system does not know anything. So it is completely inactive. No neuron is active, but at time goes to one, I input some feet forward. Uh, I place some feet forward input over here due to which the neurons in those columns are active.  
Speaker 1    00:21:07    And this forms the spouse distributor to presentations of that particular feed forward input. If I take another case, which is a predictive input, I already know that, okay, this particular feed forward input is coming along. I should be ready. I should predict something. Then the new neurons in those columns, single neurons in those columns, we see over year one, this corresponds to this, this corresponds to this are in the predictive state. So these neurons are predicting. These neurons being in a predict state, predictive state are actually predicting that my next stage, as these goes to one will be the active columns. And that actually happens over here at these goes to one, the predictive, the predictions comes through so that the neurons and the corresponding columns becomes active now because this neurons in the corresponding columns become active in the next step at these goes to two, it has to predict, predict something. Therefore it excites the nearby neuron, which is near it, like it excites the nearby neurons and changes them into the predictive state that at these goes to two, another column, another neuron in another column may become active. So this is how the SDR learns sequences and make predictions to what the next input SDR will be. It is extremely robust and, uh, which has a 40% noise tolerant. Uh, it is, uh, it is completely an unsupervised learning and it is a continuous learning in real time learns higher auto sequences. So let's take an example of, uh, example and see how it learns higher auto sequences like B, C, D, and X, B, C Y. Let's see.  
Speaker 1    00:23:14    So we have this first case before learning where I app, I applied some feet forward inputs like a, and this is the spar distributor representation of a B. This is the spar distributor representation of B C D <affirmative>. Then again, I trained another, uh, series of, uh, values like X, B, C Y.  
Speaker 1    00:23:42    Now once it, once the algorithm learns this series, a, B, C, D, then X, B, C Y. Once it learns as these things, once I input a what should the algorithm do? The algorithm should predict B, right? So therefore this firing all the neurons in the a by feet forward input will excite the neurons in the column of B to make sure there's only one neuron that gets filed in the column, which is represented by B as, as, as we know, like B is represented by if by the, by the particular column where the neuron is file. So this is the spar representation of B. Now, once it reaches B it then predicts C and this resembles this structure, the column matches over here. And once it reaches C it reaches D it predicts D it so on. Now, if I, if instead of a I input X, now, what happens over here is all the neurons gets fired.  
Speaker 1    00:24:52    This is my input over here. Now what it should be predicting, it should also be predicting B. It is still predicting B, but now the neuron that is fired is in different role, but in the C in column, similarly, it is predicting C the new room satisfied is in the different row, but in the same column, which represents the same C, and this C is then predicting Y more elaborately. If I need to look into it, what is happening is, and please seeing the input over here. Now, these neurons are predicting B over here. Like these neurons are taking the configuration of B in the predictive state, as we can see by the red points over here. And the next input is B, which is already predicted now because of this B predicted input, it'll then predict the next step C, which has a similar representation over here.  
Speaker 1    00:26:05    Now say, for example, if instead of a or X, I input B, now my algorithm does not know which B is this, is it the B from a, or is it the B from X? Let's see, what's what it does over here. So the B input excites the, um, neurons that represents both C and C bar C I'm at C double frame. So both the neurons in this column are excited over here. Similarly, you get the scene put, now the neurons in the scene put, gets activated. Now this input will then predict both the prime and Y double prime as soon over here. So this is one of the best and the most important characteristics of HDM. The characteristics of multiple predictions. Say, for example, you are tossing a coin. If you are tossing a coin, your predictions is not only head. Your predictions is also 10. So if you are detecting some animal in tossing a coin, you, you can either get head or you can either get tail. So you also have that multiple predictions in that case. And if something other than head or hotel comes up, that can be regarded justly. Similar, similar is the case of throwing a dice. It has six side, so it has six different predictions. Anything away from that, it can be regarded as animal.  
Speaker 1    00:27:47    So talking about animal animal are the data points within the data sets that appear to deviate marketly from the expected output. Animal detection refers to the problem of finding patterns in data that don't conform to expected behavior. So this the results from the Menta where they have predicted the animal for metric for some, uh, machine temperature, sensory data, as we can see this point is quite out of range out of this user range. And this point is also quite out of this user range. These are just normalities. However, the interesting thing is over here now, as we can see, if we just take the magnitude of this particular data, then this point may not be regarded as the animal. However, if we see the temporal sequence of this data, there is something happening as we can see over here, then this can be regarded as the animal.  
Speaker 1    00:28:48    In the next case, I'll explain to you, what is the flow chart of the animal detection used by HTM? So for an HTM, we have the input XT. We convert that into the sparse distributed representation. It goes through the algorithm, it calculus the prediction error, which is also known as animal score, which basically the fractions of active columns, which we are not predicting mathematically. That is the definition and prediction, error or animal score are not the, uh, standard for detecting animal. It is actually the animal likelihood, which is calculated more by modeling the distributions of error values over the window of timestamp from the past. So  
Speaker 1    00:29:46    If we can take animal score as the instantaneous animal animal likelihood can be regarded as much more concrete standard for detecting animal, which takes the order of the past timestamp as well. So once the input reaches the HTM, the end quarter wa because of the end quarter, it converts the given input into a spar presentation, and it, then it goes to spatial pull and sequence memory, and gradually, according to accordingly, whatever predicts the prediction error or, or not. And then the animal likelihood and based on the animal likelihood will come to know whether the given data or the system has an animal or not.  
Speaker 1    00:30:37    We applied this algorithm in this operate for CPU users. Data now operate for CPU uses. Data can be extracted using Theano metrics and Promeus API client. Um, so details about it are given in this GI up link over here. So once we, once we extract the data from seven time period, we will then apply our algorithm of them to see if there is animal that can, that we can find in the CPUs data or not. So let's move on to the demo. So here's the demo notebook and the code snippets are taken from the Newman target hub, uh, fork. However, I have formatted this notebook in with respect to Jupyter, uh, notebook readable format. Um, so let's move on. So here are a couple of classes which we need to install each, uh, packages, which we need to install HTM packages. The first set of data is CPU data, which we have is the increase that we have is 576.  
Speaker 1    00:31:48    The parameters value, the default parameters value like the 2%, uh, time, weekend and permanence 0.1. All these parameters values are the default parameters value given by the Numenta website. So I'm just using those values as for the period is concerned. The period is the, is the amount of time the system learns the amount of data we work before it starts trusting. So if I consider my length of is 576, if I take the period of 40, I'm just taking the considerable length of the period so that I can see some animal in the later point of the data. But in principle, the more the period, the better it is, which means the more the sample of the data, the better it is. So if we just run this notebook, let's see how it looks. So we calculate the animal score. We calculate the animal likelihood, and here we have the plots. So here we have the input signal given by the green points here, we have the animal likelihood signal. Now this animaly likelihood is definitely higher over here, higher over here, which depicts there is some animaly at this point, there is some animal at these points. Now, if we consider animal score as well in the plot, it'll see something like this.  
Speaker 1    00:33:23    Mm let's read for some time. So yeah. So this blue point is the animal score. Now, as we can see, if we go with the animal score, then almost all the points. Most of the points you see are regarded as the animal. However, that is not. So animal likelihood is the main detector of the animal. So if you go by animal likely, we do see some animality points in the plot. If we consider the real time analysis of this data, we will see something like this. The input signal in the green goes along, and, and the, there is a constant prediction that is done by the algorithm based on this input and predictions. It S the animal score at first. And at first the animal score is pretty huge because the system was, has not learned anything. The animal likelihood is pretty flat because the system does not know anything about animal. So as it moves along, it takes some animal on the process. So this is how the streamline data goes by. If we, if we take another set of data, which is much larger than this, let's see how it looks. If we take another set of data.  
Speaker 1    00:34:43    So here we can see it is 1679, and which is also not pretty big, but still like it's good for the demonstration. Uh, I I've increased the number of period by 400. So, so that the system can learn more. So if I go to my plot again, What I'll see is,  
Speaker 1    00:35:09    Um, here. So you can also see this table. Here's the time, here's the value for the CCP users. Uh, at first, the system has not predicted anything. Then the animal score is one in the beginning. Animal likelihood is very, very small in the beginning. We, we plot that those data over here. We do see, so this is the CPU uses values all over and the corresponding animal like animal score given by blue points, which shows that there's a huge, there's a huge animal in the points, but it is not the actual detector of animal. The actual detector of animal is animal likelihood given by the red. And we do see some animal in the, in the curve. If we do the realtime analysis, We do see the changing of signals. So input signals given in green, it goes away and the corresponding animal score is correspondingly calculated. And the animal likelihood is again, calculated accordingly. So this is how we do the realtime analysis of the animal detection. So going back to the presentation now, So there are a couple of commercial applications of HTM as well. Now there's a team called rock stream, which uses animal detection for, uh, proposes. There's a team called Al IO, which used, uh, this, which uses this technology in, uh, NLP, natural language processing and Semantec analysis. There's a team called intellect.com, which is from, which has originated from 2020. And it is used to detect, uh, the stock market values and for a, for a stock market prediction company to hold for more than a year, seems like a promising prospect.  
Speaker 1    00:37:13    So these are some applications of, uh, HTM in animal detection and other, uh, industries. So, uh, most of the materials in this talk are covered from new minta.com and hta.com com for community in GitHub. I would also like to thank, uh, Marcel hill who have suggested me to read on in intelligence books and which helped me to spike some of the neurons in my brain. Thank you very for this. Um, thank you very much. Uh, all the attendees for listening to the talk, you can reach out to me at this email, my LinkedIn, my getup page. And if you want to follow my individual work, the four repository is HTM applications in a I C O E AI ops. Thank you very much.  
Speaker 3    00:38:13    Uh, I have a few questions if I may ask.  
Speaker 1    00:38:16    Yes, please.  
Speaker 3    00:38:17    Uh, so very enlightening, uh, talk and presentation. Uh, I enjoyed very much, uh, everything that you have presented here, uh, when it comes now to the implementation that you have used. If I, because I tried to make a parallel with, uh, traditional time series based anomal detection, mm-hmm <affirmative> and I'm sorry, but I couldn't understand, like, what is the length of the sliding window you used in this scenario? Because I saw at some point use, like something you changed to 400, so basically used the last 400, uh, points in order to be able to predict future values.  
Speaker 1    00:38:52    Yes. So I'm not, not sure whether it's called a sightings window, but, uh, well, I just changed the period of, uh, the, an parameter and the period signifies about the, the main, uh, function of that period is how many data points can I take before the actual detection of the Anani. So new matter suggest me to take as much period as possible, probably thousand, but for that, I need to have a lot of dataset. So that's what I did. Um,  
Speaker 3    00:39:28    Yeah. I'm sorry. Let me, lemme try to rephrase that because I'm not so sure if my message was passed on correctly to you. Uh, so in traditional time series, uh, uh, predictions, uh, you have a data set of length N and, uh, usually you take a sample of length T let's say five or 10 something let's use seconds. Okay. The last five seconds in order to predict the next value. Right. And, uh, but the data format has to be three dimensional, uh, for it tend to be able to work with it if you Sensoril, for example. So the further dimension is basically the number of features that you use. If it's a unbury time, obviously it's one ed, like how many of those you have, uh, so in your case, N like the entire data set that you had, like how long it wast mm-hmm, <affirmative> the number of the values that you use to predict the next value, how long it was?  
Speaker 3    00:40:19    And the last question I have is starting at some point in time, let's, sayt zero, you know, with mm-hmm, <affirmative> that amount of value, let's say last five seconds or 10 seconds, or how many you used in order to train your, your, your network, um, how far in the future, can you go before you take a new check of the real world, you know, to see like, how far off your predictions are, you know, can you go like, just one second, can you go five seconds or 10 seconds in the future? You know, this is, uh, a point of interest, you know, that I'm, I'm actually also doing some research, you know, in time city. So that's why I'm asking all these questions.  
Speaker 1    00:40:56    Yeah. That's a very good questions, actually, really, because I, well, personally, I have not checked it like one by one, how far it should go at the moment. I'm just looking at whether it can predict something or not, uh, tell you about the predictions I have predicted in the first step and the fifth stage. So I'm taking a <affirmative> five times step window. Okay. At the moment for the predictions. So, but regarding your questions, I may need to work in this a bit so that I can answer that perfectly.  
Speaker 3    00:41:32    Okay. So I put my questions in the chat. Uh, you may have a look at them and, uh, uh, when you have an answer, you know, that you could know uh, mm-hmm, <affirmative> suggest that something then, uh, please, uh, reach back me cuz I'm really interested in this. Sure, sure. I mean, if you can also share the, the notebook that you presented mm-hmm <affirmative> then maybe I can answer the, for myself over there and also, uh, oh yeah. We can for something in the future.  
Speaker 1    00:41:57    Awesome. Awesome. Yeah. Would be great. Yeah.  
Speaker 3    00:42:00    Thank you. Thank you for time and thank you once again for the great presentation.  
Speaker 1    00:42:04    Thank you very much. Thank,  
Speaker 0    00:42:14    Thank for this amazing presentation. I think she also had a question. Um, Shane, would you want to ask this question yourself?  
Speaker 3    00:42:23    Yeah. So, uh, when you were presenting the slide with sequence prediction, I had posted a question about like how much memory, much memory would it take to and one letter. So it seemed like we had a grade of yes. Uh, like neurons and then, uh, each neuron would light up and then we would know that it was an a or something like that, but to do that, we had to represent each letter with, uh, great. Right. So I was wondering, let's say  
Speaker 1    00:43:04    No, the idea, sorry. Uh, the idea over here is like, say, for example, as a, as I understand from your questions to, to, to encode the named apple, as you said, I need to encode a, B, B E, correct. That's what a P You were saying that we need to individually encode each letter. Right,  
Speaker 3    00:43:28    Right. That's right, right.  
Speaker 1    00:43:30    But that is not the case. So for each ward, each different representation, like a may have different representation in 2048 bit of grid cells.  
Speaker 3    00:43:42    Okay.  
Speaker 1    00:43:42    Apple may have different representation. So it's each indu individualistic, uh, each representation is unique in each case.  
Speaker 2    00:43:53    Yeah.  
Speaker 3    00:43:54    Okay.  
Speaker 1    00:43:55    It's like, um, the hash function.  
Speaker 3    00:43:58    Yeah. Yeah. That's what I was thinking. So there would be collisions, right? Like, yeah. Overlaps.  
Speaker 1    00:44:05    Yes. That's, that's also the point, because if I say fruit or Apple or banana, right. They fall under the fruit column. Right. Fruit group. So they should have some overlap because there is some similar in of,  
Speaker 3    00:44:25    So you're  
Speaker 1    00:44:30    Will be, they will have some overlap. They does, they do not have complete overlap. They should not have complete overlap, but they will have some overlap. Now, if I'm talking about two mutually exclusive events, their overlap is completely zero there's nothing which represents their, the two objects are completely distinct from each other.  
Speaker 3    00:44:52    And that translates to the CPU usage application that you talked about in the way that we have, uh, representation of certain types of spikes close together in the embedded space, whereas some flats close to in the, okay. Sounds good. Yeah. Thank you.  
Speaker 1    00:45:20    Thank you for the question.  
Speaker 0    00:45:25    All right. Do we have any more questions for soya? Okay. Awesome. Thank you again, soya for an amazing presentation and thank you. You all of you for attending this meet, uh, we will send you an updated email with the presentation and the video recording and hope to see you guys again after two weeks. Thank you.  
Speaker 1    00:45:51    Thank you everyone. 

