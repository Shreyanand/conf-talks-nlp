{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdb16d7e-a9c6-4018-94f4-378c5a9ac61b",
   "metadata": {},
   "source": [
    "# Question answering from recorded videos\n",
    "\n",
    "### A list of potential questions interesting to users \n",
    "1) What was the summary of the talk?\n",
    "    * What was the key takeaway of the talk?\n",
    "    * What was the most exciting result of the project?\n",
    "\n",
    "2) What are the clusters in a playlist like Dev Conf talks?\n",
    "    Which talks are related to each other?\n",
    "    \n",
    "3) How is this talk related to topic X [AI, cloud application, Linux, open source, ...]?\n",
    "    * Find all talks/docs related to topic X?\n",
    "    * How do I demo X or How do I solve X? \n",
    "    * How can I get started with X?\n",
    "\n",
    "4) What are the links/webpages mentioned in the talk?\n",
    "\n",
    "\n",
    "### Possible videos it can be applied to\n",
    "* Dev Conf playlist on Youtube\n",
    "* Espresso series \n",
    "* Operate first channel videos\n",
    "* DS meetup videos playlist\n",
    "* Openshift channel videos\n",
    "* Open serivces group SIG, subproject meetings\n",
    "\n",
    "### Possible approaches to get text from the data\n",
    "1) Audio to text from videos\n",
    "2) Metadata\n",
    "    * Abstract, video decription, meeting notes\n",
    "3) Image to text (Video frame as images)\n",
    "\n",
    "\n",
    "### Tasks\n",
    "1) Summarization for question 1) \n",
    "2) Clustering of talks for 2)\n",
    "3) Question answering and document ranking for 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6697f95e-ed17-4171-b953-a37a82cf0843",
   "metadata": {},
   "source": [
    "# Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82adf7f8-3293-4d94-b129-9534134069be",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848103ba-151d-4e18-9f50-6bb2bbd0982b",
   "metadata": {},
   "source": [
    "## Document ranking based on the query\n",
    "#### BM-25 doc retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253313f4-279c-42cc-87d8-4d73e5ded682",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23476257-2540-4ae0-9772-c71b6e210578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# Code example from package\n",
    "corpus = [\n",
    "    \"Hello there good man!\",\n",
    "    \"It is quite windy in London\",\n",
    "    \"How is the weather today?\"\n",
    "]\n",
    "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
    "query = \"windy London\"\n",
    "tokenized_query = query.split(\" \")\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "bm25.get_top_n(tokenized_query, corpus, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e2ad2d0-cd96-4ced-a138-755fdf1ee7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Speaker 1    00:05:39    So Neo otics, we talked about HDM being a conceptu, similar to the neocortex. What is neocortex? Neocortex is the part that you are seeing the picture. It's the part of the brain covering the brain. It's the size of the large table napkin, which is like 50 by 50 square centimeters. That's it, uh, whatever I do, whatever. I think how I behave completely dependence on completely depends on this neocortex, whatever I'm speaking right now, whatever you are listening right now, it's, it's all because of these neocortex. And it, it, it constitute of 75% of the brain's volume, which is 2.5 millimeter thick. It contains almost a 20 billion neurons, tens of thousands of signups per neurons signups are the intersections just to be clear intersections, which, uh, which acts as a memory or some spike in the new one of the important characteristic is it is partially active.  \\n\"]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Application to one of the talks\n",
    "with open ('test-doc.txt', 'r') as f:\n",
    "    corpus = f.readlines()\n",
    "    \n",
    "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "query = \"What is the summary of the talk?\"\n",
    "tokenized_query = query.split(\" \")\n",
    "bm25.get_top_n(tokenized_query, corpus, n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80baa2c6-c188-4f21-8005-479f6b17dfba",
   "metadata": {},
   "source": [
    "## Doc2vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f6f3f3b-1022-400b-bc24-89b0c75114c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.1.2-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.1 MB 6.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting smart-open>=1.8.1\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 56.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.18.1\n",
      "  Downloading scipy-1.8.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 41.6 MB 77.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /opt/app-root/lib/python3.8/site-packages (from gensim) (1.22.3)\n",
      "Installing collected packages: smart-open, scipy, gensim\n",
      "Successfully installed gensim-4.1.2 scipy-1.8.0 smart-open-5.2.1\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/opt/app-root/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b888faa-0a84-4bd7-a536-dd0f0f04bf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate()]\n",
    "model = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
